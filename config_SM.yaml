# list of scenes to download and process
scenes: [
        # Heard Island
        'S1A_S3_SLC__1SSH_20220121T000105_20220121T000124_041551_04F116_EA2F'
        ]

# the name of the software. This will form part of the path
# where the products are written
software : pyrosar-snap-sm

# number of scenes to run in parallel
n_parallel: 1

#save directory for final opera products
# a sub directory for each scene will be made
pyrosar_output_folder: /data/pyroSAR/outdir

# location of SNAP installation
snap_path: /home/ec2-user/SNAP9/bin #'/Applications/snap/bin' 

# location of earthdata credentials to download data. Should be in .credentials folder
earthdata_credentials: credentials/credentials_earthdata.yaml

# location of aws credentials. Should be in .credentials folder
aws_credentials: credentials/credentials_aws.yaml

# location of copernicus data space ecosystem credentials. Should be in .credentials folder
copernicus_credentials: credentials/credentials_copernicus.yaml

# directory to save scenes
scene_folder: /data/scenes

# whether to unzip the safe file
unzip_scene: False

# directory where DEM will be saved - a sub folder is made for each DEM type
dem_folder: /data/dem

# type of dem to download for each scene
# list of valid dems in https://pypi.org/project/dem-stitcher/
dem_type: glo_30

# File path to a an existing DEM file
# leave empty to download a new one in the process
dem_path:

# Apply ETAD corrections to the slc
# Note - These must be available locally
apply_ETAD : False

# number of gdal threads to process the ETAD file with
gdal_threads : 4 

# Locally accessible folder containing ETAD files
ETAD_folder : /data/ETAD

# overwrite the dem if it already exists
overwrite_dem : True

# add a prefix to the scene in the s3 bucket
# mostly for testing, leave blank to exclude
scene_prefix: 

# specify the folder in the s3 bucket
# sar-software-comparison-Xm, qld-rainforest-timeseries-Xm-2022 daintree-rainforest-timeseries-XXXm-2024
s3_bucket_folder: experimental

# s3 bucket to push the results
# note, output crs (trg_crs) is set in opera config
# formatting will be {s3_bucket}/{s3_bucket_folder}/{opera-rtc}/{dem_type}/{trg_crs}/{prefix}{scene}/{product_id}
s3_bucket: deant-data-public-dev

# whether to push to s3
push_to_s3: True

# whether to push the DEM to the S3 bucket
upload_dem: True

# delete files after run
delete_local_files: True

#pyrosar settings - pixel size
pyrosar_spacing: 10

#pyrosar settings - scale of final product
# e.g. linear, db
pyrosar_scaling: linear

# pyrosar settings - reference area
# e.g. gamma0, sigma0, beta0 or ['gamma0','sigma0']
pyrosar_refarea: ['gamma0','sigma0']

# pyrosar settings 
# A target geographic reference system in WKT, EPSG, PROJ4 or OPENGIS format.
# See function :func:`spatialist.auxil.crsConvert()` for details.
# e.g. 4326, 3031
# set 'default' to set the crs based on the UTM location of the scene centre
# pyrosar_t_srs: default
pyrosar_t_srs: default

# turn off terrain flattening, e.g. testing for dem artifacts
# default = True (i.e. we want to perform rtc)
pyrosar_terrainFlattening : True 

# remve scattering area if no rtc
pyrosar_export_extra: ['incidenceAngleFromEllipsoid','localIncidenceAngle','DEM','layoverShadowMask','scatteringArea','gammaSigmaRatio']
# pyrosar_export_extra: ['DEM']

# a list of arguments to pass to the snap gpt interperator
# -Djava.io.tmpdir=/data/tmp -> change temp dir, fills up root space on aws
# gpt_args : ['-Djava.io.tmpdir=/data/tmp']
gpt_args : []